{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from dataHandler import load_data\n",
    "from scoring import printScoring\n",
    "\n",
    "\n",
    "# run in gpu\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_data(features,cols, method='standard'):\n",
    "#     if method == 'standard':\n",
    "#         scaler = StandardScaler()\n",
    "#     elif method == 'minmax':\n",
    "#         scaler = MinMaxScaler()\n",
    "#     else:\n",
    "#         raise ValueError('Invalid scaling method')\n",
    "#     features[cols] = scaler.fit_transform(features[cols])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def load_data(Features,Labels,target_column,scaling_method='standard', nofFeatures=20) :\n",
    "#     # duplicated row indexes\n",
    "#     duplicates = Features[Features.duplicated()].index\n",
    "#     Features.drop(duplicates, inplace=True)\n",
    "#     Labels.drop(duplicates, inplace=True)\n",
    "\n",
    "#     # drop the row if target column is missing\n",
    "#     missing_targets = Labels[Labels.isnull()].index\n",
    "#     Features.drop(missing_targets, inplace=True)\n",
    "#     Labels.drop(missing_targets, inplace=True)\n",
    "\n",
    "\n",
    "#     Features.fillna(Features.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "#     # fill missing values with mode for object columns\n",
    "#     for column in Features.columns:\n",
    "#         if Features[column].dtype == 'object':\n",
    "#             Features[column].fillna(Features[column].mode()[0], inplace=True)\n",
    "#     # Label Encoding the target column\n",
    "#     Labels = pd.DataFrame(LabelEncoder().fit_transform(Labels),columns=[target_column])\n",
    "\n",
    "#     # print(Features.isnull().sum())\n",
    "\n",
    "#     # One hot encoding the categorical columns\n",
    "#     for column in Features.columns:\n",
    "#         if Features[column].dtype == 'object':\n",
    "#             Features[column] = Features[column].astype('category')\n",
    "#     Features = pd.get_dummies(Features, drop_first=True)\n",
    "\n",
    "#     # scale the data\n",
    "#     scale_data(\n",
    "#         Features,\n",
    "#         Features.columns.difference(Features.select_dtypes(include=['bool']).columns), \n",
    "#         method=scaling_method\n",
    "#     )\n",
    "\n",
    "#     # correlation\n",
    "#     correlations = Features.corrwith(Labels[target_column]).abs().sort_values(ascending=False)\n",
    "#     # print(correlations[:20])\n",
    "\n",
    "#     Labels.reset_index(drop=True, inplace=True)\n",
    "#     Features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     top20features = Features[correlations.index[:nofFeatures]]\n",
    "#     # print(top20features)\n",
    "\n",
    "\n",
    "#     X_train, X_test, Y_train, Y_test = train_test_split(top20features, Labels, test_size=0.2,random_state=42)\n",
    "\n",
    "#     return X_train, X_test, Y_train, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Teleco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessDatasetTeleco(scaling_method ='standard',nofFeatures = 20) :\n",
    "    df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "    # drop the target rows with missing values\n",
    "    df.drop(columns=['customerID'], inplace=True)\n",
    "\n",
    "    df.replace(' ', np.nan, inplace=True)\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "    # df.dropna(subset=['Churn'], inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    Labels = df['Churn']\n",
    "    Features = df.drop(columns=['Churn'])\n",
    "    return load_data(Features,Labels,target_column='churn',scaling_method=scaling_method, nofFeatures=nofFeatures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Adult income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessDatasetAdult(scaling_method='standard', nofFeatures=20) :\n",
    "    # Fetching the dataset\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race','sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
    "    # read the data from data file\n",
    "    df = pd.read_csv('adult.data', header=None, names=column_names)\n",
    "    # add the adult test data to the df\n",
    "    df = pd.concat([df, pd.read_csv('adult.test', header=None, names=column_names)])\n",
    "    # drop the target rows with missing values or ?\n",
    "    df.replace(' ?', np.nan, inplace=True)\n",
    "    df.dropna(subset=['income'], inplace=True)\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    Labels = df['income']\n",
    "    Features = df.drop(columns=['income'])\n",
    "    # updating the labels output '>50k.' to '>50k' and '<=50k.' to '<=50k'\n",
    "    Labels.replace(' >50K.', ' >50K', inplace=True)\n",
    "    Labels.replace(' <=50K.', ' <=50K', inplace=True)\n",
    "\n",
    "\n",
    "    return load_data(Features,Labels,target_column='income',scaling_method = scaling_method, nofFeatures=nofFeatures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET creditcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preProcessDatasetCreditCard(scaling_method='minmax', nofFeatures=20):\n",
    "    df = pd.read_csv('creditcard.csv')\n",
    "    \n",
    "    positive_samples = df[df['Class'] == 1]\n",
    "    \n",
    "    negative_samples = df[df['Class'] == 0].sample(n=20000, random_state=42)\n",
    "    \n",
    "    final_df = pd.concat([positive_samples, negative_samples])\n",
    "    final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    Features = final_df.drop(columns=['Class'])\n",
    "    Labels = final_df['Class']\n",
    "\n",
    "    return load_data(Features, Labels, target_column='Class', scaling_method=scaling_method, nofFeatures=nofFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def preProcessDatasetB1(scaling_method='minmax', nofFeatures=30):\n",
    "#     final_df = pd.read_csv('B1.csv')\n",
    "#     Features = final_df.drop(columns=['y'])\n",
    "#     Labels = final_df['y']\n",
    "\n",
    "#     return load_data(Features, Labels, target_column='y', scaling_method=scaling_method, nofFeatures=nofFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuraci(y_pred, y_true) :\n",
    "#     tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "#     tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "#     fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "#     fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "#     return (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "# def sensitivity(y_pred, y_true) :\n",
    "#     # y_pred = y_pred.to_numpy().flatten()\n",
    "#     # y_true = y_true.to_numpy().flatten()\n",
    "#     tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "#     fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "#     return tp / (tp + fn)\n",
    "\n",
    "# def specificity(y_pred, y_true) :\n",
    "#     tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "#     fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "#     return tn / (tn + fp)\n",
    "\n",
    "# def precision(y_pred, y_true) :\n",
    "#     tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "#     fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "#     return tp / (tp + fp)\n",
    "\n",
    "# def f1_score(y_pred, y_true) :\n",
    "#     prec = precision(y_pred, y_true)\n",
    "#     rec = sensitivity(y_pred, y_true)\n",
    "#     return 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "# def printScoring(y_pred,y_pred_precision,y_true, retrn = False) :\n",
    "#     if retrn == True :\n",
    "#         return {\n",
    "#             'Accuracy': accuraci(y_pred, y_true),\n",
    "#             'Sensitivity': sensitivity(y_pred, y_true),\n",
    "#             'Specificity': specificity(y_pred, y_true),\n",
    "#             'Precision': precision(y_pred, y_true),\n",
    "#             'F1 Score': f1_score(y_pred, y_true),\n",
    "#             'AUROC': roc_auc_score(y_true, y_pred_precision),\n",
    "#             'AUPR': average_precision_score(y_true, y_pred_precision)\n",
    "#         }\n",
    "#     # up to 3 decimal point\n",
    "#     print()\n",
    "#     print('Accuracy : {:.7f}'.format(accuraci(y_pred, y_true)))\n",
    "#     print('Sensitivity : {:.7f}'.format(sensitivity(y_pred, y_true)))\n",
    "#     print('Specificity : {:.7f}'.format(specificity(y_pred, y_true)))\n",
    "#     print('Precision : {:.7f}'.format(precision(y_pred, y_true)))\n",
    "#     print('F1 Score : {:.7f}'.format(f1_score(y_pred, y_true)))\n",
    "#     print('AUROC : {:.7f}'.format(roc_auc_score(y_true, y_pred_precision)))\n",
    "#     print('AUPR : {:.7f}'.format(average_precision_score(y_true, y_pred_precision)))\n",
    "#     # print new line\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sigmoid function\n",
    "# def sigmoid(z) :\n",
    "#     return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# # loss function for all data points\n",
    "# def loss(y, y_pred) :\n",
    "#     # loss = -1/n * sum(y*log(h(x)) + (1-y)*log(1-h(x)))\n",
    "#     y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "#     return np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "# # gradient of loss function for all data points\n",
    "# def gradient(X, y, y_pred) :\n",
    "#     # gradient = (y-h(x))x\n",
    "#     return np.dot(X.T,y - y_pred)\n",
    "\n",
    "# def ridgeRegularization(m,theta,l2_lambda) :\n",
    "#     # regularization = (1/2m) * lambda * sum(|theta|^2)\n",
    "#     return (l2_lambda / (2 * m)) * np.sum(np.square(theta[1:])) \n",
    "\n",
    "# def lassoRegularization(m,theta,l1_lambda) :\n",
    "#     # regularization = (1/2m) * lambda * sum(|theta|)\n",
    "#     return (l1_lambda / (2 * m)) * np.sum(np.abs(theta[1:]))\n",
    "\n",
    "# def ridgeGrad(m, l2_lambda, theta, grad) :\n",
    "#     grad[1:] += (l2_lambda / m) * theta[1:]\n",
    "#     return grad\n",
    "\n",
    "# def lassoGrad(m, l1_lambda, theta, grad) :\n",
    "#     grad[1:] += (l1_lambda / m) * np.sign(theta[1:])\n",
    "#     return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LogisticRegression:\n",
    "#     def __init__(self, alpha = 0.0001, eps = 0.00001, n_iter = 1000, l2_lambda = 1, l1_lambda = 1 , regularizerType = None, theta = None):\n",
    "#         self.alpha = alpha\n",
    "#         self.n_iter = n_iter\n",
    "#         self.eps = eps\n",
    "#         self.theta = theta\n",
    "#         self.l2_lambda = l2_lambda\n",
    "#         self.l1_lambda = l1_lambda\n",
    "#         self.regularizerType = regularizerType\n",
    "    \n",
    "#     def fit(self, X, Y) :\n",
    "\n",
    "#         X = X.to_numpy().astype(float) if type(X) == pd.DataFrame else X\n",
    "#         Y = Y.to_numpy().astype(float) if type(Y) == pd.DataFrame else Y\n",
    "\n",
    "#         X = np.insert(X, 0, 1, axis=1) # add bias term to the first column\n",
    "#         Y = Y.reshape(X.shape[0], 1) # reshape Y to be a column vector\n",
    "\n",
    "\n",
    "#         # initialize theta , X and W needs to be multiplied\n",
    "#         # So theta is a column vector, row_X = column_theta\n",
    "#         if self.theta is None:\n",
    "#             self.theta = np.zeros((X.shape[1], 1))\n",
    "\n",
    "#         # print(X.shape, Y.shape, self.theta.shape)\n",
    "    \n",
    "#         iteration = 0\n",
    "#         prev_cost = -np.inf\n",
    "\n",
    "#         regularizer = {\n",
    "#             'ridge': ridgeRegularization,\n",
    "#             'lasso': lassoRegularization\n",
    "#         }\n",
    "\n",
    "#         gradients = {\n",
    "#             'ridge': ridgeGrad,\n",
    "#             'lasso': lassoGrad\n",
    "#         }\n",
    "\n",
    "#         while iteration < self.n_iter:\n",
    "#             # calculate h(x) = sigmoid(theta^T * X + b)\n",
    "#             h = sigmoid(np.dot(X, self.theta))\n",
    "\n",
    "#             regularizerCost = 0\n",
    "\n",
    "#             if self.regularizerType is not None:\n",
    "#                 regularizerCost = regularizer[self.regularizerType](X.shape[0], self.theta, self.l2_lambda)\n",
    "#             cost = loss(Y,h) + regularizerCost\n",
    "\n",
    "#             # if cost - prev_cost < self.eps:\n",
    "#             #     print(cost - prev_cost)\n",
    "#             #     print(f\"Stopping early at iteration {iteration} due to minimal change in cost.\")\n",
    "#             #     break\n",
    "\n",
    "#             # prev_cost = cost\n",
    "\n",
    "#             # print(\"cost at iteration \", iteration, \" : \", cost)\n",
    "\n",
    "#             grad = gradient(X, Y, h)\n",
    "#             if self.regularizerType is not None:\n",
    "#                 grad = gradients[self.regularizerType](X.shape[0], self.l2_lambda, self.theta, grad)\n",
    "            \n",
    "\n",
    "#             self.theta += self.alpha * grad\n",
    "#             iteration += 1\n",
    "    \n",
    "#     def predict(self,X,rtype='binary') :\n",
    "#         X = X.to_numpy().astype(float) if type(X) == pd.DataFrame else X\n",
    "#         X = np.insert(X, 0, 1, axis=1)   \n",
    "#         # print(X.shape, self.theta.shape)\n",
    "#         h = sigmoid(np.dot(X, self.theta))\n",
    "#         if rtype == 'sigmoid':\n",
    "#             return np.array(h.flatten())\n",
    "#         else:\n",
    "#             return np.array([1 if i >= 0.5 else 0 for i in h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# randomly initialize of 100 data points with 10 features between 0 and 1\n",
    "\n",
    "X = np.random.rand(12000, 30)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# randomly initialize the label of the data points 0 or 1\n",
    "Y = np.random.randint(2, size=12000)\n",
    "\n",
    "# split the data into training and testing set 80% and 20%\n",
    "# split the traing into train and validation set 80% and 20%\n",
    "\n",
    "test_size = int(0.2 * X.shape[0])\n",
    "X_test = X[:test_size]\n",
    "Y_test = Y[:test_size]\n",
    "\n",
    "print(X_test.shape, Y_test.shape)\n",
    "\n",
    "X_train = X[test_size:]\n",
    "Y_train = Y[test_size:]\n",
    "\n",
    "# Now split x_train and y_train into train and validation set\n",
    "validation_size = int(0.2 * X_train.shape[0])\n",
    "X_validation = X_train[:validation_size]\n",
    "Y_validation = Y_train[:validation_size]\n",
    "\n",
    "print(X_validation.shape, Y_validation.shape)\n",
    "\n",
    "X_train = X_train[validation_size:]\n",
    "Y_train = Y_train[validation_size:]\n",
    "\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# test the accuracy of the model\n",
    "# Y_pred = model.predict(X_validation)\n",
    "# accuracy = np.sum(Y_pred[0] == Y_validation)  / Y_validation.shape[0]\n",
    "# print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# print(Y_validation,Y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BaggingClassifer :\n",
    "#     def __init__(self, n_estimators = 10, max_samples = 1.0, n_iter = 1000, alpha = 0.0001, eps = 0.00001, l2_lambda = 1, l1_lambda = 1, regularizerType = None):\n",
    "#         self.n_estimators = n_estimators\n",
    "#         self.max_samples = max_samples\n",
    "#         self.models = []\n",
    "#         self.params = {\n",
    "#             'n_iter': n_iter,\n",
    "#             'alpha': alpha,\n",
    "#             'eps': eps,\n",
    "#             'l2_lambda': l2_lambda,\n",
    "#             'l1_lambda': l1_lambda,\n",
    "#             'regularizerType': regularizerType\n",
    "#         }\n",
    "    \n",
    "#     def fit(self, X, Y):\n",
    "#         # if dataframe\n",
    "#         X = X.to_numpy().astype(float) if type(X) == pd.DataFrame else X \n",
    "#         Y = Y.to_numpy().astype(float) if type(Y) == pd.DataFrame else Y\n",
    "\n",
    "#         # print('Bagging fit called')\n",
    "\n",
    "#         np.random.seed(42) # for reproducibility\n",
    "#         for i in range(self.n_estimators):\n",
    "#             # sample with replacement\n",
    "#             idx = np.random.choice(X.shape[0], int(self.max_samples * X.shape[0]), replace=True)\n",
    "#             model = LogisticRegression(**self.params)\n",
    "#             # print(np.unique(X[idx], axis=0).shape)\n",
    "#             model.fit(X[idx], Y[idx])\n",
    "#             self.models.append(model)\n",
    "\n",
    "#     def draw_violin_plot(self, X, Y):\n",
    "#         # Draw violin plots for each performance metric for the 9 bagging LR learners\n",
    "#         X = X.to_numpy().astype(float) if type(X) == pd.DataFrame else X \n",
    "#         Y = Y.to_numpy().astype(float) if type(Y) == pd.DataFrame else Y\n",
    "\n",
    "#         metrics_data = {\n",
    "#             'Learner': [],\n",
    "#             'Metric': [],\n",
    "#             'Value': []\n",
    "#         }\n",
    "\n",
    "#         # Calculate metrics for each model\n",
    "#         for i, model in enumerate(self.models):\n",
    "#             y_pred = model.predict(X)\n",
    "#             Accuracy = accuraci(y_pred, Y)\n",
    "#             Sensitivity = sensitivity(y_pred, Y)\n",
    "#             Specificity = specificity(y_pred, Y)\n",
    "#             Precision = precision(y_pred, Y)\n",
    "#             F1 = f1_score(y_pred, Y)\n",
    "#             y_pred = model.predict(X, rtype='sigmoid')\n",
    "#             Auroc = roc_auc_score(Y, y_pred)\n",
    "#             Aupr = average_precision_score(Y, y_pred)\n",
    "\n",
    "#             # Store metrics for plotting\n",
    "#             metrics_data['Learner'].extend([i+1] * 7)\n",
    "#             metrics_data['Metric'].extend(['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score', 'AUROC', 'AUPR'])\n",
    "#             metrics_data['Value'].extend([Accuracy, Sensitivity, Specificity, Precision, F1, Auroc, Aupr])\n",
    "\n",
    "#         metrics_df = pd.DataFrame(metrics_data)\n",
    "#         # mean and std_deviation for bagging LR learners\n",
    "\n",
    "#         mean_std = metrics_df.groupby('Metric').agg({'Value': ['mean', 'std']})\n",
    "\n",
    "#         print(\"Averege and standard deviation for bagging LR learners\")\n",
    "#         print(mean_std)\n",
    "#         print()\n",
    "\n",
    "#         # plt.figure(figsize=(14,10))\n",
    "#         # sns.violinplot(x='Metric', y='Value', data=metrics_df, inner='box')\n",
    "#         # plt.title('Performance Metrics for Bagging Logistic Regression Learners')\n",
    "#         # plt.show()\n",
    "\n",
    "#         # Plot violin plot for each metric\n",
    "#         for metric in ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score', 'AUROC', 'AUPR']:\n",
    "#             plt.figure(figsize=(3, 3))\n",
    "#             sns.violinplot(data=metrics_df[metrics_df['Metric'] == metric], x='Metric', y='Value',inner='box')\n",
    "#             plt.title(f'{metric} for 9 Bagging LR learners')\n",
    "#             plt.show()\n",
    "\n",
    "    \n",
    "#     def predict(self, X,rtype='binary') :\n",
    "\n",
    "#         X = X.to_numpy().astype(float) if type(X) == pd.DataFrame else X\n",
    "#         y_pred = np.zeros(X.shape[0])\n",
    "#         for model in self.models:\n",
    "#             y_pred += model.predict(X,rtype)\n",
    "#         y_pred /= self.n_estimators\n",
    "        \n",
    "#         return np.array([1 if i >= 0.5 else 0 for i in y_pred]) if rtype == 'binary' else y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bagging import BaggingClassifer\n",
    "# print(X)\n",
    "\n",
    "bagging_models = BaggingClassifer(n_estimators=5, max_samples=1)\n",
    "bagging_models.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bagging_models.predict(X_validation)\n",
    "accuracy = np.sum(Y_pred == Y_validation) / Y_validation.shape[0] \n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StackingClassifier :\n",
    "#     def __init__(self, bagging_models, meta_classifiier = None,alpha = 0.0001, eps = 0.00001, n_iter = 1000, l2_lambda = 1, l1_lambda = 1, regularizerType = None):\n",
    "#         self.bagging_models = bagging_models\n",
    "#         if meta_classifiier is None:\n",
    "#             meta_classifier = LogisticRegression(\n",
    "#                                     alpha , \n",
    "#                                     eps, \n",
    "#                                     n_iter, \n",
    "#                                     l2_lambda, \n",
    "#                                     l1_lambda,\n",
    "#                                     regularizerType\n",
    "#                                 )\n",
    "#         self.meta_classifier = meta_classifier\n",
    "    \n",
    "#     def fit(self, X, Y):\n",
    "#         \"\"\"Fit the bagging models for validation set\n",
    "#          add preditions of the bagging models to the feature set as columns\n",
    "#          then train the meta classifier on the old + new features\n",
    "#         \"\"\"\n",
    "#         # convert the X,Y to numpy array if the input is dataframe\n",
    "#         X = X.to_numpy().astype(float) if type(X) == pd.DataFrame else X\n",
    "#         Y = Y.to_numpy().astype(float) if type(Y) == pd.DataFrame else Y\n",
    "\n",
    "\n",
    "\n",
    "#         # converting the predictions of the bagging models into features so transpositing\n",
    "#         prediction_features = np.array([model.predict(X) for model in self.bagging_models]).T\n",
    "#         X_new = np.hstack((X, prediction_features))  \n",
    "\n",
    "#         # train the meta classifier with validation set\n",
    "#         self.meta_classifier.fit(X_new, Y)\n",
    "\n",
    "#     def predict(self, X,rtype = 'binary') :\n",
    "#         \"Predict the output of the meta classifier\"\n",
    "#         X = X.to_numpy().astype(float) if type(X) == pd.DataFrame else X\n",
    "\n",
    "#         prediction_features = np.array([model.predict(X) for model in self.bagging_models]).T\n",
    "#         X_new = np.hstack((X, prediction_features))\n",
    "#         return self.meta_classifier.predict(X_new,rtype)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stacking import StackingClassifier\n",
    "stackingClassifier = StackingClassifier(bagging_models.models)\n",
    "\n",
    "stackingClassifier.fit(X_validation, Y_validation)\n",
    "\n",
    "Y_pred = stackingClassifier.predict(X_test)\n",
    "accuracy = np.sum(Y_pred == Y_test) / Y_test.shape[0]\n",
    "\n",
    "print(\"Accuracy STacking: \", accuracy)\n",
    "\n",
    "# Logistic Regression test_set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = np.sum(y_pred == Y_test) / Y_test.shape[0]\n",
    "\n",
    "print(\"Accuracy Logistic Regression: \", accuracy)\n",
    "\n",
    "# with L2 regularization\n",
    "\n",
    "\n",
    "# Bagging test_set\n",
    "\n",
    "y_pred = bagging_models.predict(X_test)\n",
    "\n",
    "accuracy = np.sum(y_pred == Y_test) / Y_test.shape[0]\n",
    "\n",
    "print(\"Accuracy Bagging: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################      UNDO COMMENT        #########################################\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = preProcessDatasetTeleco(scaling_method='standard', nofFeatures=50)\n",
    "# X_train, X_test, Y_train, Y_test = preProcessDatasetAdult(scaling_method='standard', nofFeatures=40)\n",
    "X_train, X_test, Y_train, Y_test = preProcessDatasetCreditCard(scaling_method='standard', nofFeatures=30)\n",
    "\n",
    "validation_size = int(0.2 * X_train.shape[0])\n",
    "X_validation = X_train[:validation_size]\n",
    "Y_validation = Y_train[:validation_size]\n",
    "X_train = X_train[validation_size:]\n",
    "Y_train = Y_train[validation_size:]\n",
    "\n",
    "# Flatten the test and validation set\n",
    "Y_test = Y_test.to_numpy().flatten()\n",
    "Y_validation = Y_validation.to_numpy().flatten()\n",
    "\n",
    "\n",
    "##################################################   UNDO COMMENT #################################################\n",
    "\n",
    "# model = LogisticRegression(alpha=0.0001) # for Dataset1\n",
    "# model = LogisticRegression(l2_lambda=2, alpha=0.0001,regularizerType='ridge') # for dataset2\n",
    "model = LogisticRegression(alpha=0.0001) # for dataset 3\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"LogisticRegression scores on test set\")\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred_precision = model.predict(X_test, rtype='sigmoid')\n",
    "printScoring(Y_pred,Y_pred_precision, Y_test)\n",
    "\n",
    "\n",
    "###############################################    UNDO COMMENT     #################################################\n",
    "# bagging_models = BaggingClassifer(n_estimators=9, max_samples=1, alpha=0.0001) # DS1    \n",
    "# bagging_models = BaggingClassifer(n_estimators=9, max_samples=1, l2_lambda=2,regularizerType='ridge') # DS2\n",
    "bagging_models = BaggingClassifer(n_estimators=9, max_samples=1, alpha=0.0001) # DS3\n",
    "bagging_models.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Bagging scores on test set\")\n",
    "Y_pred = bagging_models.predict(X_test)\n",
    "Y_pred_precision = bagging_models.predict(X_test, rtype='sigmoid')\n",
    "printScoring(Y_pred,Y_pred_precision, Y_test)\n",
    "\n",
    "\n",
    "######################################################### UNDO COMMENT    ######################################\n",
    "\n",
    "\n",
    "# stackingClassifier = StackingClassifier(bagging_models.models, alpha=0.0001) # ds1\n",
    "# stackingClassifier = StackingClassifier(bagging_models.models, alpha = 0.0001,l2_lambda=2,regularizerType='ridge') # ds2\n",
    "stackingClassifier = StackingClassifier(bagging_models.models, alpha=0.0001) # for ds3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stackingClassifier.fit(X_validation, Y_validation)\n",
    "\n",
    "print(\"Stacking scores on test set\")\n",
    "Y_pred = stackingClassifier.predict(X_test)\n",
    "Y_pred_precision = stackingClassifier.predict(X_test, rtype='sigmoid')\n",
    "printScoring(Y_pred,Y_pred_precision, Y_test)\n",
    "\n",
    "bagging_models.draw_violin_plot(X_test, Y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
